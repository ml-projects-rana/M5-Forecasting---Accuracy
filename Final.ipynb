{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfIJIaoN4tno",
        "outputId": "9734d119-d148-4110-adc2-3a343e705ce2"
      },
      "source": [
        "pip install downcast"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: downcast in /usr/local/lib/python3.7/dist-packages (0.0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb0AE8aiuJ1G"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import random \n",
        "from downcast import reduce\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4Wq1TS6vdKE",
        "outputId": "cb86ee51-ab97-4afd-9d58-355ac2d6db75"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16qIHDitvxvP"
      },
      "source": [
        "calendar_=pd.read_csv('/content/drive//My Drive/CS-1/calendar.csv')\n",
        "sales_train_evaluation_=pd.read_csv('/content/drive//My Drive/CS-1/sales_train_evaluation.csv')\n",
        "sell_prices_=pd.read_csv('/content/drive//My Drive/CS-1/sell_prices.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTMJE49goQOt"
      },
      "source": [
        "* Randomly selected a Single Data point for Computation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "Zaef628x5Drm",
        "outputId": "be0d4304-abfd-45c1-bba3-6763412cfada"
      },
      "source": [
        "#https://datatofish.com/random-rows-pandas-dataframe/\n",
        "sales=sales_train_evaluation_.sample().reset_index().drop(['index'],axis=1) \n",
        "sales"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1902</th>\n",
              "      <th>d_1903</th>\n",
              "      <th>d_1904</th>\n",
              "      <th>d_1905</th>\n",
              "      <th>d_1906</th>\n",
              "      <th>d_1907</th>\n",
              "      <th>d_1908</th>\n",
              "      <th>d_1909</th>\n",
              "      <th>d_1910</th>\n",
              "      <th>d_1911</th>\n",
              "      <th>d_1912</th>\n",
              "      <th>d_1913</th>\n",
              "      <th>d_1914</th>\n",
              "      <th>d_1915</th>\n",
              "      <th>d_1916</th>\n",
              "      <th>d_1917</th>\n",
              "      <th>d_1918</th>\n",
              "      <th>d_1919</th>\n",
              "      <th>d_1920</th>\n",
              "      <th>d_1921</th>\n",
              "      <th>d_1922</th>\n",
              "      <th>d_1923</th>\n",
              "      <th>d_1924</th>\n",
              "      <th>d_1925</th>\n",
              "      <th>d_1926</th>\n",
              "      <th>d_1927</th>\n",
              "      <th>d_1928</th>\n",
              "      <th>d_1929</th>\n",
              "      <th>d_1930</th>\n",
              "      <th>d_1931</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FOODS_2_273_CA_4_evaluation</td>\n",
              "      <td>FOODS_2_273</td>\n",
              "      <td>FOODS_2</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>CA_4</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 1947 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            id      item_id  dept_id  ... d_1939 d_1940 d_1941\n",
              "0  FOODS_2_273_CA_4_evaluation  FOODS_2_273  FOODS_2  ...      0      6      0\n",
              "\n",
              "[1 rows x 1947 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUFpH2ubCnNM"
      },
      "source": [
        "#Function-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpuQc9R4bl9k"
      },
      "source": [
        "def function_1(x):\n",
        "    #Adding columns for the days d_1942 to d_1969 as nan for which we need to forecast sales\n",
        "    for i in range(1942,1970):\n",
        "      x['d_'+str(i)]=np.nan\n",
        "      x['d_'+str(i)]=x['d_'+str(i)].astype(np.float16)\n",
        "    \n",
        "    #Melting\n",
        "    #To make analysis of data in table easier we can reshape the data into a more computer-friendly form using pandas in Python. \n",
        "    #pandas.melt() is one of the function to do so\n",
        "    df=pd.melt(x,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],var_name='d',value_name='demand')\n",
        "    df=pd.merge(df,calendar_,on='d',how='left')\n",
        "    df=pd.merge(df,sell_prices_,on=['item_id','store_id','wm_yr_wk'],how='left')\n",
        "\n",
        "    #Since we got many rows with 'NaN' values in Sell Price\n",
        "    #Thus replacing 'NaN\" in 'sell_price' feature with the mean value\n",
        "    df['sell_price']=df['sell_price'].fillna(df.groupby('id')['sell_price'].transform('mean'))\n",
        "\n",
        "    #Converting Object Data Type to Category Data Type\n",
        "    col=list(df.columns)\n",
        "    types=list(df.dtypes.values)\n",
        "    for i,j in enumerate(types):\n",
        "      if j.name == 'object':\n",
        "       df[col[i]]=df[col[i]].astype('category')\n",
        "    \n",
        "    #Replacing 'NaN' values by 'no_event'\n",
        "    cat=['event_name_1','event_type_1','event_name_2','event_type_2']\n",
        "    for i in cat:\n",
        "      df[i]=df[i].cat.add_categories('no_event')\n",
        "      df[i].fillna('no_event',inplace=True)\n",
        "    \n",
        "    #Adding feature 'is_weekend' which tells about that day is weekend or not\n",
        "    f=lambda x: 1 if x<=2 else 0\n",
        "    #https://stackoverflow.com/questions/21608228/conditional-replace-pandas\n",
        "    df['is_weekend']=df['wday'].map(f) \n",
        "    df['is_weekend']=df['is_weekend'].astype(np.int8)\n",
        "    \n",
        "    #Adding feature 'month_day' which tells day of the month\n",
        "    m=df[\"date\"].tolist()\n",
        "    m=[i.split(\"-\")[2] for i in m]\n",
        "    df[\"month_day\"]=m\n",
        "    df['month_day']=df['month_day'].astype(np.int8)\n",
        "    \n",
        "    #Adding feature 'month_week_number' which tells which week of the month\n",
        "    #https://stackoverflow.com/questions/3806473/python-week-number-of-the-month\n",
        "    df['month_week_number']=(df['month_day']-1) // 7 + 1 \n",
        "    df['month_week_number']=df['month_week_number'].astype(np.int8)\n",
        "    \n",
        "    #Adding feature 'events_per_day' which tells us number of events on particular day\n",
        "    f=lambda x: 0 if x=='no_event' else 1\n",
        "    #https://stackoverflow.com/questions/21608228/conditional-replace-pandas\n",
        "    df['events_per_day']=df['event_type_1'].map(f) \n",
        "    index=df.index \n",
        "    indices=index[df['event_type_2']!='no_event'].tolist()\n",
        "    for i in indices:\n",
        "      df['events_per_day'][i]+=1\n",
        "      df['events_per_day']=df['events_per_day'].astype(np.int8)\n",
        "    \n",
        "    #Lag features are the classical way that time series forecasting problems are transformed into supervised learning problems.\n",
        "    #Lag is expressed in a time unit & corresponds to the amount of data history we allow the model to use when making the prediction.\n",
        "    #Here we have applied Lags on 'demand' column.\n",
        "    #The maximum Lags taken is 70 days \n",
        "    #https://stackoverflow.com/questions/20410312/how-to-create-a-lagged-data-structure-using-pandas-dataframe\n",
        "    lags=[28,35,42,49,56,63,70]\n",
        "    for i in lags:\n",
        "      df['lag_'+str(i)]=df.groupby(['id'])['demand'].shift(i)\n",
        "\n",
        "    #Replacing 'NaN' in 'lags' features with 0\n",
        "    lags=['lag_28','lag_35','lag_42','lag_49','lag_56','lag_63','lag_70']\n",
        "    for i in lags:\n",
        "      df[i]=df[i].fillna(0) \n",
        "    \n",
        "    #Rolling is a very useful operation for time series data.\n",
        "    #Here we have computing Rolling-Mean on 'demand' column.\n",
        "    #The maximum Window size taken is 42\n",
        "    #https://stackoverflow.com/questions/13996302/python-rolling-functions-for-groupby-object\n",
        "    #https://www.geeksforgeeks.org/python-pandas-dataframe-transform/\n",
        "    window=[7,14,28,35,42]\n",
        "    for i in window:\n",
        "      df['rolling_median_'+str(i)]=df.groupby(['id'])['demand'].transform(lambda s: s.rolling(i,center=False).median())\n",
        "\n",
        "    #Replacing 'NaN' in 'rolling_ mean' features with 0\n",
        "    window=['rolling_median_7','rolling_median_14','rolling_median_28','rolling_median_35','rolling_median_42']\n",
        "    for i in window:\n",
        "      df[i]=df[i].fillna(0) \n",
        "\n",
        "    #Encoding refers to converting the labels into numeric form so as to convert it into the machine-readable form.\n",
        "    #Machine learning algorithms can then decide in a better way on how those labels must be operated.\n",
        "    #It is an important pre-processing step for the structured dataset in supervised learning\n",
        "    #https://www.mygreatlearning.com/blog/label-encoding-in-python/\n",
        "    labelencoder=LabelEncoder() \n",
        "    category=['event_name_1','event_type_1','event_name_2','event_type_2','id','item_id','dept_id','cat_id','store_id','state_id']\n",
        "    for i in category:\n",
        "      df[i+'_']=labelencoder.fit_transform(df[i])\n",
        "\n",
        "    #Drop all the categorical columns bcoz we already added coresponding columns with label-encoding\n",
        "    df=df.drop(['event_name_1','event_type_1','event_name_2','event_type_2','id','item_id','dept_id','cat_id','store_id','state_id'],axis=1)\n",
        "\n",
        "    #Removed '_' from 'd' column values so that we can convert Categorical feature into Numerical feature easily\n",
        "    l=[]\n",
        "    for i in df['d']:\n",
        "      l.append(i.split('_')[1])\n",
        "    df['day']=l\n",
        "    #https://stackoverflow.com/questions/15891038/change-column-type-in-pandas\n",
        "    df['day']=df['day'].astype(np.int16) \n",
        "\n",
        "    #Since 'weekday' is represented by 'wday' & 'd' is represented by 'day'\n",
        "    #We already have 'month','year' thats why 'date' is also duplicate column\n",
        "    df=df.drop(['d','date','weekday'],axis=1)\n",
        "\n",
        "    df=df.drop(['demand'],axis=1)\n",
        "    df=reduce(df)\n",
        "\n",
        "    #Taken data after 1000 days (d_1000) so that processing speed will be fast (last approx. 31 months data)\n",
        "    df=df[df['day']>1000]\n",
        "\n",
        "    #Divide data into Test/Validation\n",
        "    #Validation: From d_1914 to d_1942\n",
        "    #Test: From d_1942 to d_1970\n",
        "    l=[]\n",
        "    for i in range(1914,1942):\n",
        "      l.append(i)\n",
        "    x_valid=df.loc[df['day'].isin(l)]\n",
        "    x_test=df.loc[df['day']>=1942]\n",
        "\n",
        "    #Loading Already Trained LightGBM Regressor Model for Computaion \n",
        "    with open('/content/drive//My Drive/CS-1/lgb_model.pkl','rb') as f:\n",
        "      lgb=pickle.load(f)\n",
        "\n",
        "    pred_valid=pd.DataFrame()\n",
        "    pred_test=pd.DataFrame()\n",
        "    pred_valid['id']=x['id'] \n",
        "    pred_test['id']=x['id'] \n",
        "    j=1\n",
        "    k=1\n",
        "    for i in range(1914,1942):\n",
        "      pred_valid['F'+str(j)]=lgb.predict(x_valid[x_valid['day']==(i)]) \n",
        "      j+=1\n",
        "    pred_valid[\"id\"]=pred_valid[\"id\"].apply(lambda x: x.replace('evaluation','validation'))\n",
        "\n",
        "    for i in range(1942,1970):\n",
        "      pred_test['F'+str(k)]=lgb.predict(x_test[x_test['day']==(i)]) \n",
        "      k+=1\n",
        "       \n",
        "    return pred_valid,pred_test\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wvg71-DucNta",
        "outputId": "e7c539b0-48b5-43be-c287-5da5a6ffebbe"
      },
      "source": [
        "start=time.clock() \n",
        "prediction_valid,prediction_test=function_1(sales)\n",
        "elapsed=time.clock()\n",
        "elapsed=elapsed - start\n",
        "print(\"Time spent for Predictions: \", np.round(elapsed,2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time spent for Predictions:  2.37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuO7dsD1xi2f"
      },
      "source": [
        "* Forecast Sales from Day 1914 to 1941 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "m0XPtms1rhFW",
        "outputId": "8f84c9d5-8b21-4dcc-9012-8a3ba0c25349"
      },
      "source": [
        "prediction_valid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "      <th>F20</th>\n",
              "      <th>F21</th>\n",
              "      <th>F22</th>\n",
              "      <th>F23</th>\n",
              "      <th>F24</th>\n",
              "      <th>F25</th>\n",
              "      <th>F26</th>\n",
              "      <th>F27</th>\n",
              "      <th>F28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FOODS_2_273_CA_4_validation</td>\n",
              "      <td>0.981293</td>\n",
              "      <td>0.913018</td>\n",
              "      <td>1.136423</td>\n",
              "      <td>0.505705</td>\n",
              "      <td>0.954719</td>\n",
              "      <td>0.533876</td>\n",
              "      <td>0.331676</td>\n",
              "      <td>1.0282</td>\n",
              "      <td>1.913008</td>\n",
              "      <td>2.125701</td>\n",
              "      <td>1.133325</td>\n",
              "      <td>3.221623</td>\n",
              "      <td>2.078078</td>\n",
              "      <td>1.364402</td>\n",
              "      <td>1.898234</td>\n",
              "      <td>1.772512</td>\n",
              "      <td>1.922363</td>\n",
              "      <td>1.697718</td>\n",
              "      <td>1.725335</td>\n",
              "      <td>2.126977</td>\n",
              "      <td>1.745593</td>\n",
              "      <td>1.728166</td>\n",
              "      <td>1.301806</td>\n",
              "      <td>1.329687</td>\n",
              "      <td>1.132609</td>\n",
              "      <td>0.658532</td>\n",
              "      <td>1.267908</td>\n",
              "      <td>1.002004</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            id        F1  ...       F27       F28\n",
              "0  FOODS_2_273_CA_4_validation  0.981293  ...  1.267908  1.002004\n",
              "\n",
              "[1 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7a9BKACxjYP"
      },
      "source": [
        "* Forecast Sales from Day 1942 to 1969"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100
        },
        "id": "x4B7SdQrrh0S",
        "outputId": "fbc4c174-e1f8-4eea-e0d2-8f4b559ab8ab"
      },
      "source": [
        "prediction_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>F1</th>\n",
              "      <th>F2</th>\n",
              "      <th>F3</th>\n",
              "      <th>F4</th>\n",
              "      <th>F5</th>\n",
              "      <th>F6</th>\n",
              "      <th>F7</th>\n",
              "      <th>F8</th>\n",
              "      <th>F9</th>\n",
              "      <th>F10</th>\n",
              "      <th>F11</th>\n",
              "      <th>F12</th>\n",
              "      <th>F13</th>\n",
              "      <th>F14</th>\n",
              "      <th>F15</th>\n",
              "      <th>F16</th>\n",
              "      <th>F17</th>\n",
              "      <th>F18</th>\n",
              "      <th>F19</th>\n",
              "      <th>F20</th>\n",
              "      <th>F21</th>\n",
              "      <th>F22</th>\n",
              "      <th>F23</th>\n",
              "      <th>F24</th>\n",
              "      <th>F25</th>\n",
              "      <th>F26</th>\n",
              "      <th>F27</th>\n",
              "      <th>F28</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FOODS_2_273_CA_4_evaluation</td>\n",
              "      <td>0.715647</td>\n",
              "      <td>0.704247</td>\n",
              "      <td>0.869178</td>\n",
              "      <td>0.902847</td>\n",
              "      <td>0.578938</td>\n",
              "      <td>0.853775</td>\n",
              "      <td>0.718523</td>\n",
              "      <td>0.44532</td>\n",
              "      <td>0.803831</td>\n",
              "      <td>1.00666</td>\n",
              "      <td>0.414762</td>\n",
              "      <td>0.737411</td>\n",
              "      <td>0.787071</td>\n",
              "      <td>0.654264</td>\n",
              "      <td>0.768275</td>\n",
              "      <td>0.387881</td>\n",
              "      <td>1.002529</td>\n",
              "      <td>0.790984</td>\n",
              "      <td>0.649645</td>\n",
              "      <td>0.970832</td>\n",
              "      <td>0.569661</td>\n",
              "      <td>0.876275</td>\n",
              "      <td>0.8009</td>\n",
              "      <td>1.013956</td>\n",
              "      <td>0.82274</td>\n",
              "      <td>0.711885</td>\n",
              "      <td>1.094165</td>\n",
              "      <td>0.233124</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            id        F1  ...       F27       F28\n",
              "0  FOODS_2_273_CA_4_evaluation  0.715647  ...  1.094165  0.233124\n",
              "\n",
              "[1 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovQl4PMTCfd3"
      },
      "source": [
        "#Function-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "DGDpc5OD-La2",
        "outputId": "effb7a00-9341-41e9-da90-29ecc8c6ffea"
      },
      "source": [
        "sales"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>dept_id</th>\n",
              "      <th>cat_id</th>\n",
              "      <th>store_id</th>\n",
              "      <th>state_id</th>\n",
              "      <th>d_1</th>\n",
              "      <th>d_2</th>\n",
              "      <th>d_3</th>\n",
              "      <th>d_4</th>\n",
              "      <th>d_5</th>\n",
              "      <th>d_6</th>\n",
              "      <th>d_7</th>\n",
              "      <th>d_8</th>\n",
              "      <th>d_9</th>\n",
              "      <th>d_10</th>\n",
              "      <th>d_11</th>\n",
              "      <th>d_12</th>\n",
              "      <th>d_13</th>\n",
              "      <th>d_14</th>\n",
              "      <th>d_15</th>\n",
              "      <th>d_16</th>\n",
              "      <th>d_17</th>\n",
              "      <th>d_18</th>\n",
              "      <th>d_19</th>\n",
              "      <th>d_20</th>\n",
              "      <th>d_21</th>\n",
              "      <th>d_22</th>\n",
              "      <th>d_23</th>\n",
              "      <th>d_24</th>\n",
              "      <th>d_25</th>\n",
              "      <th>d_26</th>\n",
              "      <th>d_27</th>\n",
              "      <th>d_28</th>\n",
              "      <th>d_29</th>\n",
              "      <th>d_30</th>\n",
              "      <th>d_31</th>\n",
              "      <th>d_32</th>\n",
              "      <th>d_33</th>\n",
              "      <th>d_34</th>\n",
              "      <th>...</th>\n",
              "      <th>d_1930</th>\n",
              "      <th>d_1931</th>\n",
              "      <th>d_1932</th>\n",
              "      <th>d_1933</th>\n",
              "      <th>d_1934</th>\n",
              "      <th>d_1935</th>\n",
              "      <th>d_1936</th>\n",
              "      <th>d_1937</th>\n",
              "      <th>d_1938</th>\n",
              "      <th>d_1939</th>\n",
              "      <th>d_1940</th>\n",
              "      <th>d_1941</th>\n",
              "      <th>d_1942</th>\n",
              "      <th>d_1943</th>\n",
              "      <th>d_1944</th>\n",
              "      <th>d_1945</th>\n",
              "      <th>d_1946</th>\n",
              "      <th>d_1947</th>\n",
              "      <th>d_1948</th>\n",
              "      <th>d_1949</th>\n",
              "      <th>d_1950</th>\n",
              "      <th>d_1951</th>\n",
              "      <th>d_1952</th>\n",
              "      <th>d_1953</th>\n",
              "      <th>d_1954</th>\n",
              "      <th>d_1955</th>\n",
              "      <th>d_1956</th>\n",
              "      <th>d_1957</th>\n",
              "      <th>d_1958</th>\n",
              "      <th>d_1959</th>\n",
              "      <th>d_1960</th>\n",
              "      <th>d_1961</th>\n",
              "      <th>d_1962</th>\n",
              "      <th>d_1963</th>\n",
              "      <th>d_1964</th>\n",
              "      <th>d_1965</th>\n",
              "      <th>d_1966</th>\n",
              "      <th>d_1967</th>\n",
              "      <th>d_1968</th>\n",
              "      <th>d_1969</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FOODS_2_273_CA_4_evaluation</td>\n",
              "      <td>FOODS_2_273</td>\n",
              "      <td>FOODS_2</td>\n",
              "      <td>FOODS</td>\n",
              "      <td>CA_4</td>\n",
              "      <td>CA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 1975 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                            id      item_id  dept_id  ... d_1967 d_1968 d_1969\n",
              "0  FOODS_2_273_CA_4_evaluation  FOODS_2_273  FOODS_2  ...    NaN    NaN    NaN\n",
              "\n",
              "[1 rows x 1975 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97IPfBSx_6Vl"
      },
      "source": [
        "sales=sales.iloc[:,:-28]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sz2DTcqXw1Fh"
      },
      "source": [
        "def function_2(x,y_test):\n",
        "  #Inserting columns for the days d_1914 to d_1941 as nan for which we need to forecast sales.\n",
        "  #Bcoz from days d_1914 to d_1941 we also have true labels \n",
        "  #Thus it will be good to use this range of data for getting RMSE value \n",
        "  for i in range(1914,1942):\n",
        "    x['d_'+str(i)]=np.nan\n",
        "    x['d_'+str(i)]=x['d_'+str(i)].astype(np.float16)\n",
        "    \n",
        "  #Melting\n",
        "  #To make analysis of data in table easier we can reshape the data into a more computer-friendly form using pandas in Python. \n",
        "  #pandas.melt() is one of the function to do so\n",
        "  df=pd.melt(x,id_vars=['id','item_id','dept_id','cat_id','store_id','state_id'],var_name='d',value_name='demand')\n",
        "  df=pd.merge(df,calendar_,on='d',how='left')\n",
        "  df=pd.merge(df,sell_prices_,on=['item_id','store_id','wm_yr_wk'],how='left')\n",
        "  \n",
        "  #Since we got many rows with 'NaN' values in Sell Price\n",
        "  #Thus replacing 'NaN\" in 'sell_price' feature with the mean value\n",
        "  df['sell_price']=df['sell_price'].fillna(df.groupby('id')['sell_price'].transform('mean'))\n",
        "\n",
        "  #Converting Object Data Type to Category Data Type\n",
        "  col=list(df.columns)\n",
        "  types=list(df.dtypes.values)\n",
        "  for i,j in enumerate(types):\n",
        "    if j.name == 'object':\n",
        "      df[col[i]]=df[col[i]].astype('category')\n",
        "\n",
        "  #Replacing 'NaN' values by 'no_event'\n",
        "  cat=['event_name_1','event_type_1','event_name_2','event_type_2']\n",
        "  for i in cat:\n",
        "    df[i]=df[i].cat.add_categories('no_event')\n",
        "    df[i].fillna('no_event',inplace=True)\n",
        "\n",
        "  #Adding feature 'is_weekend' which tells about that day is weekend or not\n",
        "  f=lambda x: 1 if x<=2 else 0\n",
        "  #https://stackoverflow.com/questions/21608228/conditional-replace-pandas\n",
        "  df['is_weekend']=df['wday'].map(f) \n",
        "  df['is_weekend']=df['is_weekend'].astype(np.int8)\n",
        "\n",
        "  #Adding feature 'month_day' which tells day of the month\n",
        "  m=df[\"date\"].tolist()\n",
        "  m=[i.split(\"-\")[2] for i in m]\n",
        "  df[\"month_day\"]=m\n",
        "  df['month_day']=df['month_day'].astype(np.int8)\n",
        "\n",
        "  #Adding feature 'month_week_number' which tells which week of the month\n",
        "  #https://stackoverflow.com/questions/3806473/python-week-number-of-the-month\n",
        "  df['month_week_number']=(df['month_day']-1) // 7 + 1 \n",
        "  df['month_week_number']=df['month_week_number'].astype(np.int8)\n",
        "    \n",
        "  #Adding feature 'events_per_day' which tells us number of events on particular day\n",
        "  f=lambda x: 0 if x=='no_event' else 1\n",
        "  #https://stackoverflow.com/questions/21608228/conditional-replace-pandas\n",
        "  df['events_per_day']=df['event_type_1'].map(f) \n",
        "  index=df.index \n",
        "  indices=index[df['event_type_2']!='no_event'].tolist()\n",
        "  for i in indices:\n",
        "    df['events_per_day'][i]+=1\n",
        "    df['events_per_day']=df['events_per_day'].astype(np.int8)\n",
        "\n",
        "  #Lag features are the classical way that time series forecasting problems are transformed into supervised learning problems.\n",
        "  #Lag is expressed in a time unit & corresponds to the amount of data history we allow the model to use when making the prediction.\n",
        "  #Here we have applied Lags on 'demand' column.\n",
        "  #The maximum Lags taken is 70 days \n",
        "  #https://stackoverflow.com/questions/20410312/how-to-create-a-lagged-data-structure-using-pandas-dataframe\n",
        "  lags=[28,35,42,49,56,63,70]\n",
        "  for i in lags:\n",
        "    df['lag_'+str(i)]=df.groupby(['id'])['demand'].shift(i)\n",
        "\n",
        "  #Replacing 'NaN' in 'lags' features with 0\n",
        "  lags=['lag_28','lag_35','lag_42','lag_49','lag_56','lag_63','lag_70']\n",
        "  for i in lags:\n",
        "    df[i]=df[i].fillna(0) \n",
        "\n",
        "  #Rolling is a very useful operation for time series data.\n",
        "  #Here we have computing Rolling-Mean on 'demand' column.\n",
        "  #The maximum Window size taken is 42\n",
        "  #https://stackoverflow.com/questions/13996302/python-rolling-functions-for-groupby-object\n",
        "  #https://www.geeksforgeeks.org/python-pandas-dataframe-transform/\n",
        "  window=[7,14,28,35,42]\n",
        "  for i in window:\n",
        "    df['rolling_median_'+str(i)]=df.groupby(['id'])['demand'].transform(lambda s: s.rolling(i,center=False).median())\n",
        "\n",
        "  #Replacing 'NaN' in 'rolling_ mean' features with 0\n",
        "  window=['rolling_median_7','rolling_median_14','rolling_median_28','rolling_median_35','rolling_median_42']\n",
        "  for i in window:\n",
        "    df[i]=df[i].fillna(0) \n",
        "\n",
        "  #Encoding refers to converting the labels into numeric form so as to convert it into the machine-readable form.\n",
        "  #Machine learning algorithms can then decide in a better way on how those labels must be operated.\n",
        "  #It is an important pre-processing step for the structured dataset in supervised learning\n",
        "  #https://www.mygreatlearning.com/blog/label-encoding-in-python/\n",
        "  labelencoder=LabelEncoder() \n",
        "  category=['event_name_1','event_type_1','event_name_2','event_type_2','id','item_id','dept_id','cat_id','store_id','state_id']\n",
        "  for i in category:\n",
        "    df[i+'_']=labelencoder.fit_transform(df[i])\n",
        "\n",
        "  #Drop all the categorical columns bcoz we already added coresponding columns with label-encoding\n",
        "  df=df.drop(['event_name_1','event_type_1','event_name_2','event_type_2','id','item_id','dept_id','cat_id','store_id','state_id'],axis=1)\n",
        "\n",
        "  #Removed '_' from 'd' column values so that we can convert Categorical feature into Numerical feature easily\n",
        "  l=[]\n",
        "  for i in df['d']:\n",
        "    l.append(i.split('_')[1])\n",
        "  df['day']=l\n",
        "  #https://stackoverflow.com/questions/15891038/change-column-type-in-pandas\n",
        "  df['day']=df['day'].astype(np.int16) \n",
        "\n",
        "  #Since 'weekday' is represented by 'wday' & 'd' is represented by 'day'\n",
        "  #We already have 'month','year' thats why 'date' is also duplicate column\n",
        "  df=df.drop(['d','date','weekday'],axis=1)\n",
        "\n",
        "  df=df.drop(['demand'],axis=1)\n",
        "  df=reduce(df)\n",
        "\n",
        "  #Taken data after 1000 days (d_1000) so that processing speed will be fast (last approx. 31 months data)\n",
        "  df=df[df['day']>1000]\n",
        "  \n",
        "  #Test: From d_1913 to d_1941\n",
        "  x_test=df.loc[df['day']>1913]\n",
        "    \n",
        "  #Loading Already Trained LightGBM Regressor Model for Computaion\n",
        "  with open('/content/drive//My Drive/CS-1/lgb_model.pkl','rb') as f:\n",
        "    lgb=pickle.load(f)\n",
        "\n",
        "  pred_test=lgb.predict(x_test) \n",
        "  rmse=np.sqrt(((pred_test-y_test)**2).mean())\n",
        "  \n",
        "  return rmse\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_JC_Sxepj1-",
        "outputId": "3d053355-11e5-4ff9-8ae8-87d077fdb210"
      },
      "source": [
        "#https://stackoverflow.com/questions/5478351/python-time-measure-function\n",
        "start=time.clock()\n",
        "rmse=function_2(sales.iloc[:,:-28],sales.iloc[:,-28:].values.tolist())\n",
        "elapsed=time.clock()\n",
        "elapsed=elapsed - start\n",
        "print(\"Time spent: {}\".format(np.round(elapsed,2)))\n",
        "print(\"Rmse: {}\".format(np.round(rmse,3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time spent: 2.07\n",
            "Rmse: 1.343\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}